<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>01 - Wprowadzenie</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="_static/github-markdown.css" />
  <link rel="stylesheet" href="_static/custom.css" />
  <link rel="icon" type="image/x-icon" href="_static/favicon.ico" />
  <script>
  MathJax = {
      tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
      fontCache: 'global'
      }
  };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<main class="markdown-body">
<header id="title-block-header">
<h1 class="title">01 - Wprowadzenie</h1>
</header>
<h1 id="wprowadzenie-do-przetwarzania-obrazów">Wprowadzenie do przetwarzania obrazów</h1>
<h2 id="politechnika-poznańska-instytut-robotyki-i-inteligencji-maszynowej">Politechnika Poznańska, Instytut Robotyki i Inteligencji Maszynowej</h2>
<p align="center">
  <img width="180" height="180" src="_static/logo.svg">
</p>

<h2 id="ćwiczenie-laboratoryjne-1-wstęp"><strong>Ćwiczenie laboratoryjne 1: Wstęp</strong></h2>
<p><a href="/lab-wdpo">Powrót do spisu treści ćwiczeń laboratoryjnych</a></p>
<h1 id="wstęp">Wstęp</h1>
<p>Na zajęciach wykorzystywać będziemy język programowania Python oraz biblioteki dedykowane przetwarzaniu obrazów oraz -- w mniejszym stopniu -- uczeniu maszynowemu.</p>
<p>Python to język programowania wysokiego poziomu ogólnego przeznaczenia, o rozbudowanym pakiecie bibliotek standardowych, którego ideą przewodnią jest czytelność i klarowność kodu źródłowego. Jego składnia cechuje się przejrzystością i zwięzłością. Python wspiera różne paradygmaty programowania: obiektowy, imperatywny oraz w mniejszym stopniu funkcyjny. Posiada w pełni dynamiczny system typów i automatyczne zarządzanie pamięcią, będąc w tym podobnym do języków Perl, Ruby, Scheme czy Tcl. Podobnie jak inne języki dynamiczne jest często używany jako język skryptowy. Interpretery Pythona są dostępne na wiele systemów operacyjnych. Python rozwijany jest jako projekt Open Source zarządzany przez Python Software Foundation, która jest organizacją non-profit. Standardową implementacją języka jest CPython (napisany w C), ale istnieją też inne. (<a href="https://pl.wikipedia.org/wiki/Python">źródło: Wikipedia</a>)</p>
<h2 id="kroki-instalacji-interpretera-pythona-w-systemie-windows">Kroki instalacji interpretera Pythona w systemie Windows</h2>
<details>
  <summary>Rozwiń</summary>

<p>Aby rozpocząć pracę z językiem Python należy pobrać jego interpreter.</p>
<p>Proszę pobrać dystrybucję Pythona w wersji 3.9.7 (najnowsza dostępna na dzień 2021.09.20):</p>
<p><a href="https://www.python.org/ftp/python/3.9.7/python-3.9.7-amd64.exe">https://www.python.org/ftp/python/3.9.7/python-3.9.7-amd64.exe</a></p>
<p>A następnie zainstalować. Na pierwszym ekranie należy zaznaczyć opcję: Add Python 3.9 to PATH</p>
  <p align="center">
    <img width="656" height="109" src="./_01 - Wprowadzenie_readme_files/python_path.png">
  </p>

<p>Pominięcie tej opcji uniemożliwi uruchomienie Pythona oraz jego narzędzi z konsoli, a także spowoduje, że IDE nie wykryje automatycznie lokalizacji interpretera.</p>
<blockquote>
<p><strong>Uwaga:</strong><br />
Po zainstalowaniu Pythona należy zrestartować komputer (w celu odświeżenia przez system zmiennej PATH).</p>
</blockquote>
<p><strong>Dodatkowe pakiety (biblioteki)</strong></p>
<p>W celu instalacji dodatkowych bibliotek wykorzystane zostanie narzędzie pip obsługiwane przez wykorzystywane środowisko programistyczne. Biblioteki do zainstalowania: <code>opencv-contrib-python</code>, <code>scikit-image</code>, <code>matplotlib</code> Szczegóły przeprowadzenia tego procesu zostały omówione przy opisie tworzenia pierwszego projektu.</p>
</details>

<BR>

<h2 id="kroki-instalacji-ide-pycharm">Kroki instalacji IDE PyCharm</h2>
<details>
  <summary>Rozwiń</summary>

<p>Na zajęciach wykorzystywane jest środowisko programistyczne PyCharm, które dostępne jest pod adresem:</p>
<p><a href="https://www.jetbrains.com/pycharm/">https://www.jetbrains.com/pycharm/</a></p>
<p>Przy pierwszym uruchomieniu zostaną Państwo poproszeni o wybór schematu klawiszy (w przypadku przyzwyczajenia do skrótów klawiszowych z Visual Studio warto wybrać tę opcję) oraz schematu kolorów (np. Darcula).</p>
<blockquote>
<p><strong>Uwaga:</strong><br />
Po instalacji wszystkich elementów przy pisaniu programu w PyCharm powinny pokazywać się podpowiedzi dotyczące dostępnych funkcji. W celu ich wywołania należy wcisnąć Ctrl+Spacja po napisaniu kilku pierwszych liter. Aby podejrzeć argumenty wywoływanej funkcji, należy, mając kursor pomiędzy nawiasami nacisnąć Ctrl+Shift+Spacja. Możliwe jest również najechanie na funkcje wskaźnikiem myszki z wciśniętym klawiszem Ctrl.</p>
</blockquote>
</details>

<BR>

<h2 id="wykorzystywane-biblioteki">Wykorzystywane biblioteki</h2>
<ul>
<li><p><strong>OpenCV</strong> (<code>opencv-contrib-python</code>)</p>
<p>Największa i najbardziej znana biblioteka służąca do przetwarzania obrazów. Początkowo napisana w języku C, obecnie w C++, ale posiadająca zbiór wrapperów umożliwiających wywoływanie funkcji m.in. w języku Python czy Java.</p>
<p><a href="https://docs.opencv.org/5.x/index.html">Dokumentacja (API Reference)</a></p>
<details>
  <summary>Jak czytać dokumentację w OpenCV - tipy</summary>

<p>Bazując na przykładzie funkcji <code>cv2.cvtColor</code>, którego dokumentacja znajduje się pod <a href="https://docs.opencv.org/5.x/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab">tym linkiem</a>, można zauważyć, że:</p>
<ul>
<li><p>na początku pokazano dokumentację dla języka C++, a dopiero następnie dla języka Pythona. W przypadku Pythona, w pierwszej linijce znajduje się informacja, że funkcja ta jest dostępna w module <code>cv2</code> lub <code>cv.</code>.</p></li>
<li><p>następnie zapoznać się można z opisem funkcji, a czasem zasadą działania algorytmu, przykładowym użyciem oraz występującymi typami danych.</p></li>
<li><p>na końcu można znaleźć opis i typy parametrów wejściowych oraz wartości zwracane przez funkcję.</p></li>
</ul>
</details><BR>
</li>
<li><p><strong>Numpy</strong> (<code>numpy</code>)</p>
<p>Biblioteka do przetwarzania tablic i macierzy. W szczególności wykorzystywana do operacji matematycznych.</p>
<p><a href="https://numpy.org/doc/stable/">Dokumentacja</a></p></li>
<li><p><strong>Scikit-image</strong> (<code>scikit-image</code>)</p>
<p>Biblioteka do przetwarzania obrazów, napisana w składni i paradygmacie języka Python. Brak obsługi video.</p>
<p><a href="https://scikit-image.org/">Dokumentacja</a></p></li>
</ul>
<h2 id="tworzenie-pierwszego-projektu-w-ide">Tworzenie pierwszego projektu w IDE</h2>
<details>
  <summary>Rozwiń</summary>

<p>Należy uruchomić PyCharm a następnie utworzyć nowy projekt. Okno podczas pierwszego uruchomienia przedstawiono poniżej. Przy kolejnych uruchomieniach ładowany będzie poprzedni projekt i w celu utworzenia nowego należy wybrać <em>File</em>-&gt;<em>New Project</em>.</p>
<p align="center">
  <img width="786" height="593" src="./_01 - Wprowadzenie_readme_files/pycharm_new_project_start.png">
</p>

<p>Proszę zwrócić uwagę na nazwę oraz lokalizację projektu.</p>
<p><strong>UWAGA</strong></p>
<p>W nazwie oraz lokalizacji projektu zalecamy nie stosować polskich znaków diakrytycznych oraz spacji (używać podkreślników). Podczas tworzenia nowego projektu domyślnie wybrana jest opcja utworzenia nowego środowiska wirtualnego (virtualenv), które izoluje Państwa projekt i jest preferowanym podejściem (np. jedno środowisko wirtualne dla wszystkich projektów z przedmiotu). Różne wirtualne środowiska mogą zawierać różne biblioteki i/lub wersje tych samych bibliotek.</p>
<p><strong>Na zajęciach w laboratorium, ze względów technicznych proszę jednak wybrać opcję <em>Existing interpreter</em></strong></p>
<p align="center">
  <img width="786" height="593" src="./_01 - Wprowadzenie_readme_files/pycharm_new_project_interpreter.png">
</p>

<p>Pierwsze uruchomienie skutkuje błędem <No interpreter> i w celu jego eliminacji należy nacisnąć znajdujący się z prawej strony przycisk z trzema kropkami, a następnie wybrać System Interpreter (domyślna lokalizacja: <code>C:\Users\lab\AppData\Local\Programs\Python\Python39\python.exe</code>) jak na rysunku poniżej. Potwierdzić przyciskiem ok.</p>
<p align="center">
  <img width="786" height="593" src="./_01 - Wprowadzenie_readme_files/pycharm_new_project_interpreter_system.png">
</p>

<p>Ostatecznie okno tworzenia nowego projektu powinno wyglądać jak poniżej:</p>
<p align="center">
  <img width="786" height="593" src="./_01 - Wprowadzenie_readme_files/pycharm_new_project_interpreter_final.png">
</p>

<p>Przy pierwszym uruchomieniu (<strong>w laboratorium nie jest to konieczne, gdyż wszystko już jest zainstalowane</strong>) należy zainstalować dodatkowe biblioteki. W tym celu z menu <em>File</em> wybrać <em>Settings</em>, a następnie <em>Project: &lt;nazwa_projektu&gt;</em> i <em>Project interpreter</em>. Po prawej stronie znajduje się przycisk z plusem, który umożliwia instalację dodatkowych pakietów.</p>
<p align="center">
  <img width="786" height="593" src="./_01 - Wprowadzenie_readme_files/pycharm_new_project_interpreter_packages.png">
</p>

<p>Należy następnie w okno wyszukiwania wpisywać i zainstalować następujące pakiety (poczekać do końca instalacji przed dodaniem kolejnej): <em>matplotlib</em>, <em>opencv-contrib-python</em>, <em>scikit-image</em></p>
<p align="center">
  <img width="926" height="753" src="./_01 - Wprowadzenie_readme_files/pycharm_packages_opencv.png">
</p>

<p>Możemy teraz dodać nowy plik *.py i wkleić przykładowy program zamieszczony poniżej, uruchomić go i obserwować efekty działania.</p>
</details>

<BR>

<h2 id="pierwszy-program">Pierwszy program</h2>
<p>Wklej do pliku <code>main.py</code> następujący kod. Uruchom i zaobserwuj efekty jego działania:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="im">import</span> cv2</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a><span class="kw">def</span> main():</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a>    cap <span class="op">=</span> cv2.VideoCapture(<span class="dv">0</span>)  <span class="co"># open the default camera</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a>    key <span class="op">=</span> <span class="bu">ord</span>(<span class="st">&#39;a&#39;</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true"></a>    <span class="cf">while</span> key <span class="op">!=</span> <span class="bu">ord</span>(<span class="st">&#39;q&#39;</span>):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true"></a>        <span class="co"># Capture frame-by-frame</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true"></a>        ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true"></a>        <span class="co"># Our operations on the frame comes here</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true"></a>        <span class="co"># Convert RGB image to grayscale</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true"></a>        img_gray <span class="op">=</span> cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true"></a>        <span class="co"># Blur the image</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true"></a>        img_filtered <span class="op">=</span> cv2.GaussianBlur(img_gray, (<span class="dv">7</span>, <span class="dv">7</span>), <span class="fl">1.5</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true"></a>        <span class="co"># Detect edges on the blurred image</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true"></a>        img_edges <span class="op">=</span> cv2.Canny(img_filtered, <span class="dv">0</span>, <span class="dv">30</span>, <span class="dv">3</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true"></a>        <span class="co"># Display the result of our processing</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true"></a>        cv2.imshow(<span class="st">&#39;result&#39;</span>, img_edges)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true"></a>        <span class="co"># Wait a little (30 ms) for a key press - this is required to refresh the image in our window</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true"></a>        key <span class="op">=</span> cv2.waitKey(<span class="dv">30</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true"></a>    <span class="co"># When everything done, release the capture</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true"></a>    cap.release()</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true"></a>    <span class="co"># and destroy created windows, so that they are not left for the rest of the program</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true"></a>    cv2.destroyAllWindows()</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&#39;__main__&#39;</span>:</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true"></a>    main()</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true"></a></span></code></pre></div>
<blockquote>
<p><strong>Uwaga!</strong><br />
Zwróć uwagę na cyfrę <code>0</code> w linii <code>cap = cv2.VideoCapture(0)</code>. Oznacza ona numer kamerki, która zostanie użyta do przechwytywania obrazu. W przypadku, gdybyśmy chcieli użyć innej kamerki, należy podać jej numer. W przypadku, gdybyśmy chcieli użyć pliku wideo, należy podać ścieżkę do pliku wideo.</p>
</blockquote>
<h2 id="wczytywanie-zapisywanie-i-wyświetlanie-obrazów">Wczytywanie, zapisywanie i wyświetlanie obrazów</h2>
<p>Znajdź w <a href="https://docs.opencv.org/5.x/db/deb/tutorial_display_image.html">dokumentacji</a> funkcje <code>cv2.imread</code>, <code>cv2.imwrite</code> oraz <code>cv2.imshow</code>.</p>
<blockquote>
<p><strong>Uwaga:</strong><br />
Funkcja <code>cv2.imread</code> jako drugi parametr przyjmuje flagę informującą o sposobie wczytywania obrazu. Flaga <code>cv2.IMREAD_COLOR</code> w przypadku wczytywania obrazu kolorowego oraz <code>cv2.IMREAD_GRAYSCALE</code> w przypadku obrazu w skali szarości. Szczegóły w dokumentacji: <a href="https://docs.opencv.org/5.x/d8/d6a/group__imgcodecs__flags.html#ga61d9b0126a3e57d9277ac48327799c80">ImreadModes</a>.</p>
</blockquote>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Wyszukaj i pobierz z internetu dowolny obraz. Następnie, wczytaj go, wyświetl na ekranie i zapisz pod inną nazwą korzystając z powyższych funkcji. Znajdź nowo zapisany plik na dysku.</p>
<blockquote>
<p><strong>Uwaga:</strong><br />
Umieść obraz w tym samym katalogu co plik <code>main.py</code> lub podaj pełną ścieżkę do pliku.</p>
</blockquote>
<h2 id="obrazy-a-piksele---przechowywanie-obrazu-w-pamięci">Obrazy a piksele - przechowywanie obrazu w pamięci</h2>
<p>Obraz wczytany z pliku lub pobrany z kamery przejwia pewne istotne cechy:</p>
<ul>
<li><p>jest przechowywany jako macierz (tablica) typu <code>numpy.array</code></p></li>
<li><p>jego rozmiar to: <code>wysokość_obrazu x szerokość_obrazu x liczba_kanałów</code>, gdzie:</p>
<ul>
<li>szerokość i wysokość to rozdzielczość wyrażona w pikselach</li>
<li>liczba kanałów określa ile składowych ma dany piksel (3 w przypadku obrazu kolorowego i 1 w przypadku obrazu w skali szarości).</li>
</ul></li>
<li><p>wartość każdego piksela mieści się w zakresie 0 -- 255.</p></li>
</ul>
<p>Poniżej zamieszczono wycinek obrazu wraz z wartościami jasności poszczególnych kanałów dla wszystkich pikseli w otoczeniu. Obraz kolorowy (BGR) - każdy piksel ma trzy kanały, czyli przechowuje trzy wartości:</p>
<p align="center">
  <img width="403" height="346" src="./_01 - Wprowadzenie_readme_files/sample_img_pixels.png">
</p>

<p>Obraz w skali szarości (grayscale) - każdy piksel ma jeden kanał, czyli przechowuje jedną wartość:</p>
<p align="center">
  <img width="456" height="399" src="./_01 - Wprowadzenie_readme_files/sample_img_pixels_gray.png">
</p>

<p>Kształt macierzy przechowującej obraz po wczytaniu można sprawdzić za pomocą komend (obie działają identycznie):</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="bu">print</span>(np.shape(<span class="op">&lt;</span>nazwa_macierzy<span class="op">&gt;</span>))</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a><span class="bu">print</span>(<span class="op">&lt;</span>nazwa_macierzy<span class="op">&gt;</span>.shape)</span></code></pre></div>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Przetestuj działanie powyższych funkcji na wczytanym obrazie (lub kilku obrazach).</p>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Zapoznaj się z informacjami dostępnymi pod <a href="https://docs.opencv.org/5.x/d3/df2/tutorial_py_basic_ops.html">linkiem</a>, które dotyczą podstawowych operacji na macierzach obrazowych. Następnie korzystając z obraz ...   Korzystając z obrazu z poprzedniego zadania, odczytaj wartość jasności piksela w położeniu 220, 270 kiedy obraz jest wczytany jako kolorowy oraz kiedy obraz jest wczytany w skali szarości. Zwróć uwagę na liczbę otrzymywanych wartości.</p>
<blockquote>
<p><strong>Uwaga:</strong><br />
W celu połączenia zmiennych z istniejącym tekstem można wykorzystać tak zwane f-string: <code>print(f'Pixel value at [220, 270]: {px}')</code></p>
<p>Zwróć uwagę na literę <code>f</code> przed cudzysłowem otwierającym ciąg tekstowy - powoduje ona, że kod wpisany wewnątrz ciągu tekstowego pomiędzy klamrami <code>{}</code> będzie wykonany jako kod Pythonowy i w jego miejsce zostanie wstawiona zwrócona wartość. Dla dociekliwych: dobre podsumowanie starszych i obecnych możliwości formatowania tekstu w języku Python znajduje się <a href="https://realpython.com/python-f-strings/">tutaj</a>.</p>
</blockquote>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Wycinając dowolny prostokąt (często nazywany obszarem zainteresowania - ROI), zduplikuj fragment obrazu, wyświetl go w osobnym oknie, a następnie wklej w inne miejsce oryginalnego obrazu.</p>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Wykorzystaj funkcję <code>cv2.cvtColor</code> i zmień format kolorów z domyślnego dla OpenCV <code>BGR</code> na szeroko używany <code>RGB</code>. Wyświetl oba obrazy za pomocą <code>cv2.imshow</code>). Zwróć uwagę, jak ta zmiana wypłynęła na obrazy.</p>
<blockquote>
<p><strong>Uwaga:</strong><br />
Skąd rozbieżność między światem RGB a formatem BGR w OpenCV? Odpowiedź możesz znaleźć w <a href="https://stackoverflow.com/questions/14556545/why-opencv-using-bgr-colour-space-instead-of-rgb">tym pytaniu</a>.</p>
</blockquote>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Pobierz obraz wyświetlony poniżej (prawy przycisk myszy -&gt; "Zapisz grafikę jako..."). Korzystając z funkcji <code>cv2.split</code> podzielić obraz na trzy składowe i w trzech niezależnych oknach wyświetlić osobno składową czerwoną, niebieską oraz zieloną.</p>
<p>Funkcja <code>cv2.split</code> jest kosztowna obliczeniowo. Wykorzystaj wielowymiarowe indeksowanie numpy (<em>slicing</em> - preferowany sposób w Pythonie) do uzyskania tego samego efektu.</p>
<p align="center">
  <img width="320" height="320" src="./_01 - Wprowadzenie_readme_files/AdditiveColor.png">
</p>

<h2 id="obsługa-kamer-oraz-wideo">Obsługa kamer oraz wideo</h2>
<p>Biblioteka OpenCV zapewnia identyczny interfejs dostępu do poszczególnych klatek obrazu dla kamer oraz plików wideo. W obu przypadkach wykorzystywana jest ta sama klasa <code>cv2.VideoCapture</code>, którą inicjalizujemy inną wartością, tj. numerem kamery lub nazwą pliku wideo. Dalsza obsługa jest w obu przypadkach identyczna. Zapoznaj się z <a href="https://docs.opencv.org/5.x/dd/d43/tutorial_py_video_display.html">przykładem</a>.</p>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Jeśli komputer jest wyposażony w kamerę to otwórz ją i wczytuj kolejne klatki po naciśnięciu klawisza spacja.</p>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Pobierz <a href="https://chmura.put.poznan.pl/s/9fCBoHsrrzn5Twx">plik wideo</a> i wczytaj z niego kolejne klatki jak w przypadku kamery. Dodaj obsługę zdarzenia polegającego na wykryciu końca pliku. W tym celu wykorzystaj wartość <em>true/false</em> zwracaną przez metodę <code>read</code> klasy VideoCapture.</p>
<h2 id="zadania-do-samodzielnej-realizacji">Zadania do samodzielnej realizacji</h2>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Dla przypomnienia podstaw języka Python wykonaj zadania z interaktywnego notatnika: <a href="https://colab.research.google.com/drive/1h9ZuXPR-WKHT5giNJdlF6TAhPjRgSS0k?usp=sharing">https://colab.research.google.com/drive/1h9ZuXPR-WKHT5giNJdlF6TAhPjRgSS0k?usp=sharing</a></p>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>OpenCV nie jest jedyną biblioteką do przetwarzania obrazów w Pythonie. Inną, również popularną biblioteką jest <code>scikit-image</code>. Została ona napisana w języku Python jako dedykowana biblioteka do przetwarzania obrazów. Charakteryzuje ją bardzo bogata dokumentacja i zbiór przykładów.</p>
<p>Zapoznaj się z <a href="https://scikit-image.org/docs/stable/user_guide/getting_started.html">pierwszymi krokami</a> oraz <a href="https://scikit-image.org/docs/dev/auto_examples/">zbiorem przykładów</a>.</p>
<p><span class="emoji" data-emoji="boom">💥</span> <strong>Zadanie do wykonania</strong> <span class="emoji" data-emoji="boom">💥</span></p>
<p>Zrealizować prosty pokaz zdjęć z wybranego folderu: wybór następnego/poprzedniego zdjęcia ma się odbywać za pomocą dwóch różnych klawiszy (np. q, w). Pokaz ma być cykliczny, np. po osiągnięciu ostatniego zdjęcia i wciśnięciu klawisza ‘następny’ wczytywać się ma pierwsze zdjęcie.</p>
</main>
</body>
</html>
